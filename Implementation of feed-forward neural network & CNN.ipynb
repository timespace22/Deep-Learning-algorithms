{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vyqLinsY6bpy",
   "metadata": {
    "id": "vyqLinsY6bpy"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "initial_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874ac4b",
   "metadata": {
    "id": "7874ac4b"
   },
   "source": [
    "Concretely, this project is split into two parts:\n",
    "\n",
    "- **Part I: play with feed-forward neural network**\n",
    "    - Build your feed-forward network with different layers and activation functions\n",
    "    - Define the gradient descent function to update the parameters\n",
    "    - Adjust the learning rate to achieve better performance \n",
    "    - Run the evaluation function\n",
    "\n",
    "\n",
    "- **Part II: implement your own Convolutional Neural Network**\n",
    "    - Train the CNN and compare it with the feed-forward neural network\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5511f2",
   "metadata": {
    "id": "1f5511f2"
   },
   "source": [
    "## 1. Package\n",
    "\n",
    "Let's first import all the packages that you will need.\n",
    "\n",
    "- **torch, torch.nn, torch.nn.functional** are the fundamental modules in pytorch library, supporting Python programs that facilitates building deep learning projects.\n",
    "- **torchvision** is a library for Computer Vision that goes hand in hand with PyTorch\n",
    "- **numpy** is the fundamental package for scientific computing with Python programs.\n",
    "- **matplotlib** is a library to plot graphs and images in Python.\n",
    "- **math, random** are the standard modules in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882eba3d",
   "metadata": {
    "id": "882eba3d"
   },
   "outputs": [],
   "source": [
    "# pip install torch\n",
    "# pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb862f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aeb862f",
    "outputId": "fe3d6c72-38cd-4c90-da65-9ec213725a5b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from project1_utils import *\n",
    "\n",
    "print(\"Import packages successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d8bb5",
   "metadata": {
    "id": "ae4d8bb5"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a530f8",
   "metadata": {
    "id": "e7a530f8"
   },
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63334fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c63334fa",
    "outputId": "45883895-870e-4f9a-c819-589efeabb549"
   },
   "outputs": [],
   "source": [
    "# the number of images in a batch\n",
    "batch_size = 32\n",
    "\n",
    "# load dataset\n",
    "\n",
    "trainset = dataset(path='dataset/trainset.h5')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = dataset(path='dataset/testset.h5')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# name of classes\n",
    "classes = ('cat', 'dog')\n",
    "\n",
    "print (\"Number of training examples: \" + str(trainset.length))\n",
    "print (\"Number of testing examples: \" + str(testset.length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34752a1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "34752a1c",
    "outputId": "3e8e7586-6166-405d-81e2-7b26e4ccb5a6"
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "num_toshow = 10\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:num_toshow]))\n",
    "\n",
    "# print labels\n",
    "_, indexs = torch.max(labels, 1) \n",
    "print(' '.join('%5s' % classes[indexs[j]] for j in range(num_toshow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c58c54",
   "metadata": {
    "id": "45c58c54"
   },
   "source": [
    "## 3. Build your feedforward neural network.\n",
    "\n",
    "In this cell, you will be required to build a **three-layer multilayer perceptron (MLP)** to classify images into different categories. \n",
    "\n",
    "<!-- As we know from the class, **each layer** of a MLP can be denoted as the following mathematical operation:\n",
    "\n",
    "$$z = W^T x + b$$ $$a = \\sigma(z)$$\n",
    "\n",
    "Here, $W, b$ denote the weights and biases, and $a, \\sigma$ denote activation output and activation function, respectively.\n",
    "**The function is parameterized by $W, b$ as well as the choice of $\\sigma(\\cdot)$**.\n",
    "\n",
    "Note that it is valid for $\\sigma(\\cdot)$ to be the identity function, or $z = \\sigma(z)$.\n",
    "\n",
    "----\n",
    "\n",
    "**Question 1 (6 points):** Now, let's implement functions at the layer level to do the following:\n",
    "\n",
    "Hint: To implement $W^Tx+b$ in PyTorch, one way is to write it as `x.mm(W) + b`. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f616622",
   "metadata": {
    "id": "5f616622"
   },
   "source": [
    "The size of input images is a batch-like tensor $ X \\in \\mathbb{R}^{B \\times C \\times H \\times W}$, where $B$ denotes the batch size. Vectorize the image pixels equals to transforming into a vector $X_{vector} \\in \\mathbb{R}^{B \\times CHW}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f0306",
   "metadata": {
    "id": "284f0306"
   },
   "outputs": [],
   "source": [
    "def image_vectorization(image_batch):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        image_batch: a batch of images with shape [b, c, h, w]\n",
    "    Output: \n",
    "        vectorized_image_batch: a batch of neurons\n",
    "    \"\"\"\n",
    "    \n",
    "    # vectorize the image pixels\n",
    "    flat = nn.Flatten()\n",
    "    vectorized_image_batch = flat(image_batch)\n",
    "\n",
    "    return vectorized_image_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059bbbb",
   "metadata": {
    "id": "1059bbbb"
   },
   "source": [
    "As we know from the class, **each layer** of a MLP can be denoted as the following mathematical operation:\n",
    "\n",
    "$$z = W^T x + b$$ \n",
    "\n",
    "Here, $W, b$ denote the weights and biases. The function is **parameterized by $W, b$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32728243",
   "metadata": {
    "id": "32728243"
   },
   "outputs": [],
   "source": [
    "def get_layer_params(input_dim: int, output_dim: int):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        input_dim: number of neurons in the input\n",
    "        output_dim: number of neurons produced by the layer\n",
    "    Output: \n",
    "        a dictionary of generated parameters\n",
    "            - w: weights\n",
    "            - b: biases\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate the parameters\n",
    "    w = nn.Parameter(torch.Tensor(output_dim,input_dim), requires_grad =True)\n",
    "    b = nn.Parameter(torch.Tensor(output_dim), requires_grad =True)\n",
    "    \n",
    "    return {'w': w,\n",
    "            'b': b}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f1fa8",
   "metadata": {
    "id": "8d7f1fa8"
   },
   "source": [
    "Following with the previous linear layer, an activation layer is required to add non-linearity to the network:\n",
    "\n",
    " $$a = \\sigma(z)$$\n",
    "\n",
    " $a, \\sigma$ denote activation output and activation function, respectively.\n",
    "The entire layer function is also **parameterized by choice of $\\sigma(\\cdot)$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34390a64",
   "metadata": {
    "id": "34390a64"
   },
   "outputs": [],
   "source": [
    "def activation_wrapper(z, activation='relu'):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        x: the input neuron values\n",
    "        activation: name of activation, could be one in ['relu', 'sigmoid', 'tanh']\n",
    "    Output: \n",
    "        a: the corresponding activated output\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "      if activation == 'relu':\n",
    "          for i in range(z.shape[0]):\n",
    "            for j in range(z.shape[1]):\n",
    "              z[i][j] = max(0,z[i][j])\n",
    "\n",
    "      elif activation == 'sigmoid':\n",
    "          for i in range(z.shape[0]):\n",
    "            for j in range(z.shape[1]):\n",
    "              z[i][j] = 1/(1 + np.exp(-z[i][j]))\n",
    "\n",
    "      elif activation == 'tanh':\n",
    "          for i in range(z.shape[0]):\n",
    "            for j in range(z.shape[1]):\n",
    "              z[i][j] = (np.exp(z[i][j]) - np.exp(-z[i][j]))/(np.exp(z[i][j]) + np.exp(-z[i][j]))\n",
    "\n",
    "    a = z\n",
    "\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed6494",
   "metadata": {
    "id": "c1ed6494"
   },
   "outputs": [],
   "source": [
    "def layer_forward_computation(x, params, activation):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        x: the input to the layer\n",
    "        params: parameters of each layer\n",
    "        activation: activation type\n",
    "    Output: \n",
    "        a: the output after the activation\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the output for layer\n",
    "    z = torch.mm(x, torch.t(params['w'])) + params['b']\n",
    "\n",
    "    a = activation_wrapper(z, activation)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607eef82",
   "metadata": {
    "id": "607eef82"
   },
   "source": [
    "---\n",
    "\n",
    "Back to building our three-layer MLP for classification. If you have implemented the functions above correctly,\n",
    "now the processing of putting everything together will be very easy.\n",
    "\n",
    "Just like other parts of your programming experience,\n",
    "knowing how to efficiently abstract and modularize components of your program will be critical in deep learning.\n",
    "\n",
    "**Architecture Requirement**:\n",
    "\n",
    "We now describe in details how our three-layer MLP should be built in PyTorch.\n",
    "\n",
    "1. In the dataset, the size of input image is a tensor $ X \\in \\mathbb{R}^{B \\times 3 \\times 32 \\times 32}$, where $B$ denotes the batch size.\n",
    "2. Vectorize the image pixels to a vector $X_{vector} \\in \\mathbb{R}^{B \\times 3072}$.\n",
    "3. We now begin describing the specific architecture of the model, although this is not the only design choice, and feel free to change the hidden dimensions of the parameters\n",
    "4. Layer1: set your parameters so the input is projected from $\\mathbb{R}^{B \\times 3072}$ to $\\mathbb{R}^{B \\times 256}$, use ReLU as your activation function\n",
    "5. Layer2: set your parameters so the input is projected from $\\mathbb{R}^{B \\times 256}$ to $\\mathbb{R}^{B \\times 128}$, use ReLU as your activation function\n",
    "6. Layer3: set your parameters so the input is projected from $\\mathbb{R}^{B \\times 128}$ to $\\mathbb{R}^{B \\times 2}$, use sigmoid function as your activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25124b1",
   "metadata": {
    "id": "b25124b1"
   },
   "outputs": [],
   "source": [
    "layer1_params: dict = dict()\n",
    "layer2_params: dict = dict()\n",
    "layer3_params: dict = dict()\n",
    "\n",
    "\n",
    "\n",
    "def net(X, params, activations):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X: the input images to the network\n",
    "        params: a dictionary of parameters(W and b) for the three different layers\n",
    "        activations: a dictionary of activation function names for the three different layers\n",
    "    Output: \n",
    "        output: the final output from the third layer\n",
    "    \"\"\"\n",
    "    # build your network forward\n",
    "\n",
    "    vectorized_image_batch = image_vectorization(X)\n",
    "\n",
    "    layer1_output = layer_forward_computation(vectorized_image_batch, params['layer1'], activations['layer1'])\n",
    "\n",
    "    layer2_output = layer_forward_computation(layer1_output, params['layer2'], activations['layer2'])\n",
    "\n",
    "    output = layer_forward_computation(layer2_output, params['layer3'], activations['layer3'])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe70b2d",
   "metadata": {
    "id": "abe70b2d"
   },
   "outputs": [],
   "source": [
    "\"\"\" We prepare serval dictories to store the parameters and activations for different   \"\"\"\n",
    "layer1_params: dict = dict()\n",
    "layer2_params: dict = dict()\n",
    "layer3_params: dict = dict()\n",
    "params: dict = dict()\n",
    "activations: dict = dict()\n",
    "\n",
    "layer1_params = get_layer_params(3072, 256)\n",
    "layer2_params = get_layer_params(256, 128)\n",
    "layer3_params = get_layer_params(128, 2)\n",
    "\n",
    "params['layer1'] = layer1_params\n",
    "params['layer2'] = layer2_params\n",
    "params['layer3'] = layer3_params\n",
    "\n",
    "# Three activation function options: ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "activations['layer1'] = 'relu'\n",
    "activations['layer2'] = 'relu'\n",
    "activations['layer3'] = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sd2PN7nNJnzv",
   "metadata": {
    "id": "sd2PN7nNJnzv"
   },
   "outputs": [],
   "source": [
    "output = net(images, params, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef13176",
   "metadata": {
    "id": "9ef13176"
   },
   "source": [
    "## 4. Backpropagation and optimization\n",
    "\n",
    "After finishing the forward pass, you now need to compute gradients for all Tensors with `requires_grad=True`, e.g., parameters of layer1. These gradients will be used to update parameters via gradient descent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a89c01",
   "metadata": {
    "id": "70a89c01"
   },
   "source": [
    "Gradient descent is a way to minimize the final objective function (loss) parameterized by a model's parameter $\\theta$ by updating the parameters in the opposite direction of the gradient $\\nabla_\\theta J(\\theta)$ w.r.t to the parameters. The learning rate $\\lambda$ determines the size of the steps you take to reach a (local) minimum.\n",
    "\n",
    "However, for the vanilla gradient descent, you need to run through all the samples in your training set and update once. This will be time-consuming with large-scale datasets. We are doing Stochastic Gradient Descent, which only requires a subset of training samples to update the parameters. With the popular deep learning framework, the subset usually equals to the minibatch selected during training.\n",
    "\n",
    "Now, let's look at the equation to update parameters for each layer in your network.\n",
    "\n",
    "$$\\large \\theta = \\theta - \\lambda\\cdot\\nabla_\\theta J(\\theta)$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cceed",
   "metadata": {
    "id": "758cceed"
   },
   "outputs": [],
   "source": [
    "def update_params(params, learning_rate):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        params: the dictornary to store all the layer parameters\n",
    "        learning_rate: the step length to update the parameters\n",
    "    Output: \n",
    "        params: the updated parameters\n",
    "    \"\"\"\n",
    "        \n",
    "    #TODO: update the parameters of each layer\n",
    "    with torch.no_grad():\n",
    "       for k in params:\n",
    "         params[k]['w'] -= learning_rate * params[k]['w'].grad\n",
    "         params[k]['b'] -= learning_rate * params[k]['b'].grad\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026ef65",
   "metadata": {
    "id": "8026ef65"
   },
   "source": [
    "Since you are updating the parameters for each batch of data iteratively, you will need to clear the gradients after each update. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abdc66",
   "metadata": {
    "id": "50abdc66"
   },
   "outputs": [],
   "source": [
    "def zero_grad(params):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        params: the dictornary to store all the layer parameters\n",
    "    Output: \n",
    "        params: the updated parameters with gradients clear\n",
    "    \"\"\"\n",
    "    for k in params:\n",
    "      params[k]['w'].grad.zero_()\n",
    "      params[k]['b'].grad.zero_()\n",
    "\n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96138ea",
   "metadata": {
    "id": "d96138ea"
   },
   "source": [
    "\n",
    "With the function **update_params( )** and **zero_grad( )** you have defined, you can move to the backpropagation process. The process includes computing gradients, updating parameters, reset gradients, think of how to combine them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c6fff",
   "metadata": {
    "id": "d41c6fff"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def backprop(loss, params, learning_rate):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        loss: the loss tensor from the objective funtion that can be used to compute gradients\n",
    "        params: parameters of the three layers\n",
    "        learning_rate: the size of steps when updating parameters\n",
    "    Output:\n",
    "        params: parameters after one backpropogation\n",
    "    \"\"\"    \n",
    "    loss.backward()\n",
    "    update_params(params, learning_rate)\n",
    "    zero_grad(params)\n",
    "\n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de02f38",
   "metadata": {
    "id": "2de02f38"
   },
   "source": [
    "\n",
    "## 5. Training loop\n",
    "\n",
    "For this binary classification task, a standard objective function **Binary Cross-Entropy Loss** is used. Related detail is given as follows:\n",
    "\n",
    "$$\\large L = -\\frac{1}{N}\\sum_{i=1}^{N}( y_i \\cdot \\log(p(y_i))+(1-y_i)\\log(1-p(y_i)))$$\n",
    "\n",
    "where $y$ is the label (1 for dog and 0 for cat in our case) and $p(y)$ is the predicted probability, here $N$ equals to the batch_size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75d74f",
   "metadata": {
    "id": "ac75d74f"
   },
   "source": [
    "Before moving into the training loop, it's usually a good practice to have a learning rate decay function. The reason is that when your model is training for a longer time, it's closer to the optimal convergence. Therefore, a lower learning rate will improve the learning of complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a057c8",
   "metadata": {
    "id": "17a057c8"
   },
   "outputs": [],
   "source": [
    "def adjust_lr(learning_rate, epoch):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        learning_rate: the input learning rate\n",
    "        epoch: which epoch you are in\n",
    "    Output:\n",
    "        learning_rate: the updated learning rate\n",
    "    \"\"\"    \n",
    "\n",
    "    # for every 15 epochs it will decay\n",
    "    if (epoch + 1)%15 == 0 and epoch != 0:\n",
    "      learning_rate = learning_rate*0.1\n",
    "\n",
    "    return learning_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed12c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9ed12c6",
    "outputId": "9190be31-428f-4075-fef7-09a8b89f674f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# define the initial learning rate here\n",
    "learning_rate = 1e-2\n",
    "n_epochs = 30 # how many epochs to run\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# initialize network parameters\n",
    "init_params(params)\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward\n",
    "        output = net(inputs, params, activations)\n",
    "        \n",
    "        # Compute the loss using the final output\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        params = backprop(loss, params, learning_rate)\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 200 == 199:  # print every 200 mini-batches\n",
    "            print('[Epoch %d, Step %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # adjust learning rate\n",
    "    learning_rate = adjust_lr(learning_rate, epoch)\n",
    "print('Finished Training')\n",
    "\n",
    "print('Time taken : ' + str((time.time() - start_time)/60) + ' mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60078912",
   "metadata": {
    "id": "60078912"
   },
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dbfa1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "cb9dbfa1",
    "outputId": "efb0b342-4cd2-4c61-f319-118257f1da6e"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "_, labels = torch.max(labels, 1)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(10)))\n",
    "\n",
    "output = net(images, params, activations)\n",
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d5189",
   "metadata": {
    "id": "e01d5189"
   },
   "source": [
    "**Evaluation**: Now testing with your trained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45304e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d45304e",
    "outputId": "121f17a8-ee5d-47c2-f869-0d6d7774a799"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since you're not training, you don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        output = net(images, params, activations)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 2000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda3a70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dda3a70",
    "outputId": "b073553e-d33b-44b0-affe-5ffaf2d9f691"
   },
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        output = net(images, params, activations)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                         accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be2bff",
   "metadata": {
    "id": "23be2bff"
   },
   "source": [
    "# Part II\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Build your convolutional neural network.\n",
    "\n",
    "So far, you have tried feed-forward network on image classification, but the performance is not satisfying. Why? \n",
    "The reason is that vectorizing the images will lose some critical patterns of images, such as edges, corners, and local structures. Instead, convolutional neural network is very good at capturing these patterns. \n",
    "\n",
    "To explore this, let's build a CNN to see how good it is in image classification!\n",
    "\n",
    "---\n",
    "Lets build a two-layer CNN with a maxpooling layer in between.\n",
    "Note that one Fully-Connected (FC) layer will follow the CNN network to map image features into class features. Overall, this network is similar to the one you built above, with the first two feed-forward layers being replaced by the convolutional layers:\n",
    "\n",
    "            image -> [CNN layer 1] -> [CNN layer 2] -> vectorization -> [FC layer] -> prediction\n",
    "\n",
    "**Architecture Requirement**:\n",
    "\n",
    "1. CNN Layer1: suggests that **3 or 5** as your convolution kernel size; the number of output channels can be selected from **[16, 32, 64]**; use ReLU as your activation function\n",
    "2. CNN Layer2: suggests that **3 or 5** as your convolution kernel size; the number of output channels can be selected from **[128, 256]**; use ReLU as your activation function\n",
    "3. FC layer: set your parameters, so the input is projected from $\\mathbb{R}^{B \\times N}$ to $\\mathbb{R}^{B \\times 2}$, $N$ is defined by your CNN layers' parameters; use sigmoid function as your activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cce6e",
   "metadata": {
    "id": "fa6cce6e"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define your layers here!! \n",
    "        self.cnn_layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size = 5), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        \n",
    "        self.cnn_layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 256, kernel_size = 3), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "\n",
    "        self.FC_layer = torch.nn.Sequential(\n",
    "            nn.Linear(6*6*256, 2),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        # raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Your forward pass with the defined layers\n",
    "        cnn_l1_out = self.cnn_layer1(x)\n",
    "        cnn_l2_out = self.cnn_layer2(cnn_l1_out)\n",
    "        vectorized_image_batch = image_vectorization(cnn_l2_out)\n",
    "        output = self.FC_layer(vectorized_image_batch)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ded0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b5ded0d",
    "outputId": "d943362c-b7a6-4a42-d5f3-95adb1d2c5f5"
   },
   "outputs": [],
   "source": [
    "# define the initial learning rate here\n",
    "import time\n",
    "starting = time.time()\n",
    "learning_rate = 1e-2\n",
    "n_epochs = 30 # how many epochs to run\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCELoss()\n",
    "cnn_net = Net()\n",
    "optimizer = torch.optim.SGD(cnn_net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward \n",
    "        output = cnn_net(inputs)\n",
    "        \n",
    "        # Compute the loss using the final output\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # print every 200 mini-batches\n",
    "            print('[Epoch %d, Step %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "print('Time taken : ' + str((time.time() - starting)/60) + ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc52fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bfc52fe",
    "outputId": "3070d75f-2ab9-43c2-a77d-8522c8792d45"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since you're not training, you don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        output = cnn_net(images)\n",
    "\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 2000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d735d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea9d735d",
    "outputId": "d0b953a3-3754-424c-e068-ce55e95a793f"
   },
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        output = cnn_net(images)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                         accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4b70c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bb4b70c",
    "outputId": "48acfc2e-c1e2-4628-b9c7-dfc524644f9d"
   },
   "outputs": [],
   "source": [
    "print(\"Total time taken : \" + str((time.time() - initial_time)/60) + \" mins\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
